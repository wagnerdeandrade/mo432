{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wagner Rogério de Andrade RA 036546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hltghrALPa3j"
   },
   "source": [
    "# Pré processamento\n",
    "* Leia o arquivo Bias_correction_ucl.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ECGurZLNKFbP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00514/Bias_correction_ucl.csv\"\n",
    "original_ko_temp_forecast_df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e8dfkCypPk96"
   },
   "source": [
    "* Remova a coluna \"Next_Tmin\".\n",
    "* Remova a coluna Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y5zmsRZKNaKa"
   },
   "outputs": [],
   "source": [
    "ko_temp_forecast_df = original_ko_temp_forecast_df.drop(['Next_Tmin', 'Date'], \\\n",
    "                                                        axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIYx_ClxRYvu"
   },
   "source": [
    "* Remova as linhas que tem valor faltante. Das 7752 linhas originais sobram 7588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKb0X7-aRLPD",
    "outputId": "cac0b0df-ac01-4b0b-b7a5-5ecc155de093"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7752, 23)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_temp_forecast_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_fpGHT7OQ-0g"
   },
   "outputs": [],
   "source": [
    "ko_temp_forecast_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yLzKjdWkRRni",
    "outputId": "fa7abe8f-cb77-4c96-d7a8-cda9dc61199c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7588, 23)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ko_temp_forecast_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1y726WHQABI"
   },
   "source": [
    "* O atributo de saída é Next_Tmax (a temperatura máxima no próximo dia). Vamos removê-lo do conjunto de dados para evitar contaminação durante o processo de normalização.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "okDUeGTnSOTx"
   },
   "outputs": [],
   "source": [
    "next_tmax = ko_temp_forecast_df['Next_Tmax']\n",
    "ko_temp_forecast_df.drop('Next_Tmax', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8CUSXL9rSJV3"
   },
   "source": [
    "* Centralize e normalize cada atributo de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IyTwr9RCQOJa",
    "outputId": "3bf8715c-7fdd-43b6-abdd-b5f778f7cb8f"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "prep_ko_temp_forecast_np = preprocessing.scale(ko_temp_forecast_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DCW3x_eajcS7"
   },
   "source": [
    "# Busca de hiperparâmetros e modelos utilizando:\n",
    "* 5 fold cross validation como técnica de resampling separando os dados em conjuntos de 70% de treino e 30% de teste;\n",
    "* RMSE como medida de erro;\n",
    "* Busca aleatória de hiperparametros (nos modelos aplicáveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "2zVXNTlNkyXk"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Numero de vezes em que serão gerados valores aleatórios de hiperparâmetros \n",
    "# no teste\n",
    "HYPERPARAM_SAMPLING_N = 10\n",
    "\n",
    "\n",
    "# Calcula e returna o valor de RMSE score no conjunto de dados fornecido \n",
    "# usando o modelo especificado.\n",
    "#\n",
    "# X = conjunto de entrada (feature set)\n",
    "# y = conjunto alvo (target ou class)\n",
    "# cv = cross validator to be used by sklearn.model_selection\n",
    "#      cross_val_score in order to determine the RMSE\n",
    "#      default: ShuffleSplit with 5 fold on 70% test set\n",
    "#\n",
    "# Returns: RMSE value\n",
    "#\n",
    "# Reference: https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "def x_val_positive_rmse(model, X, y, cv = ShuffleSplit(\\\n",
    "                                                    n_splits=5, \\\n",
    "                                                    test_size=0.3)):\n",
    "    scores = cross_val_score(model, \\\n",
    "                             X, \\\n",
    "                             y,\n",
    "                             cv = ShuffleSplit(n_splits=5, test_size=0.3), \\\n",
    "                             scoring=('neg_root_mean_squared_error'))\n",
    "    return np.mean(- scores)\n",
    "\n",
    "# Calcula e retorna o valor do RMSE score da execução de um modelo usando \n",
    "# x_val_positive_rmse sem nenhum parâmetro especial bem como seu correspondente\n",
    "# RMSE score melhor ajustado para HYPERPARAM_SAMPLING_N valores aleatoriamente\n",
    "# escolhidos de hiperparâmetros conforme estipulado por tunned_model_lambda\n",
    "#\n",
    "# X = conjunto de entrada (feature set)\n",
    "# y = conjunto alvo (target ou class)\n",
    "# defaul_model = the default model \n",
    "# tunned_model_lambda = a lambda function that generates a model with tunned\n",
    "#                       hyperparameters\n",
    "#\n",
    "# Returns:\n",
    "#     default_params_RMSE: the RMSE value without any tunning parameter\n",
    "#     best_params_RMSE the RMSE value with tunning parameters\n",
    "def model_default_vs_tunned_compare(defaul_model, tunned_model_lambda, X, y):\n",
    "\n",
    "    default_params_RMSE = x_val_positive_rmse(defaul_model, X, y)\n",
    "\n",
    "    best_params_RMSE = 10**3\n",
    "    for i in range(HYPERPARAM_SAMPLING_N):\n",
    "        mean_iter_scores = x_val_positive_rmse(tunned_model_lambda(), X, y)\n",
    "\n",
    "        if best_params_RMSE > mean_iter_scores:\n",
    "            best_params_RMSE = mean_iter_scores  \n",
    "    \n",
    "    return default_params_RMSE, best_params_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QnqsfecklqF"
   },
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKF1pFBwSfKs",
    "outputId": "093ec01b-37d1-4c14-e55b-2217a2293f95"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "traditional_lr_rmse = x_val_positive_rmse(LinearRegression(), \\\n",
    "                                          prep_ko_temp_forecast_np,\\\n",
    "                                          next_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzXd7B0Aq1OA"
   },
   "source": [
    "## Linear com regularização L2\n",
    "Sendo alpha escolhido com: 10 números aleatórios entre 10^-3 e 10^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "L4ePqFvjksq1"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = lambda: Ridge(alpha=random.uniform(10**-3, 10**3))\n",
    "\n",
    "default_ridge_lr_RMSE, best_ridge_lr_RMSE = \\\n",
    "    model_default_vs_tunned_compare(Ridge(), \\\n",
    "                                    ridge,\\\n",
    "                                    prep_ko_temp_forecast_np,\\\n",
    "                                    next_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CK2D4OyqBwuF"
   },
   "source": [
    "## Linear com regularização L1\n",
    "Sendo alpha escolhido com: 10 números aleatórios entre 10^-3 e 10^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "t_MpmqCM7D4P"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = lambda: Lasso(alpha=random.uniform(10**-3, 10**3))\n",
    "\n",
    "default_lasso_lr_RMSE, best_lasso_lr_RMSE = \\\n",
    "    model_default_vs_tunned_compare(Lasso(), \\\n",
    "                                    lasso, \\\n",
    "                                    prep_ko_temp_forecast_np,\\\n",
    "                                    next_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyMj4s18FFAp"
   },
   "source": [
    "## SVM Linear\n",
    "Sendo 10 amostras aleatórias com epsilon sendo 0.1 ou 0.3 e C entre 2^-5 e 2^15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "-5NKu4QyFD4R",
    "outputId": "d0da949e-1e68-44fb-b8bf-9f0ddd8e6a57"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svr_linear = lambda: LinearSVR(C = random.uniform(2**-5, 2**15), \\\n",
    "                               epsilon = random.choice([0.1, 0.3]))\n",
    "\n",
    "default_svr_linear_RMSE, best_svr_linear_RMSE = \\\n",
    "    model_default_vs_tunned_compare(LinearSVR(), \\\n",
    "                                    svr_linear, \\\n",
    "                                    prep_ko_temp_forecast_np, \\\n",
    "                                    next_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5OcZRfzakMs"
   },
   "source": [
    "## SVM com kernel RBF\n",
    "Sendo 10 amostras aleatórias com epsilon sendo 0.1 ou 0.3, C entre 2^-5 e 2^15 e gamma entre 2^-9 e 2^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mfYQ1rNoHDN1",
    "outputId": "c00397b7-08d4-4c86-a4c2-88ac344ffdbb"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr = lambda: SVR(epsilon = random.choice([0.1, 0.3]), \\\n",
    "                  C = random.uniform(2**-5, 2**15), \\\n",
    "                  gamma = random.uniform(2**-9, 2**3), \\\n",
    "                  kernel='rbf')\n",
    "\n",
    "default_svr_rbf_RMSE, best_svr_rbf_RMSE = \\\n",
    "    model_default_vs_tunned_compare(SVR(kernel='rbf'), \\\n",
    "                                    svr, \\\n",
    "                                    prep_ko_temp_forecast_np, \\\n",
    "                                    next_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xZlTH2ca-Jy"
   },
   "source": [
    "## KNN\n",
    "Sendo K: 10 números aleatórios entre 1 e 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rX30dV5Eafgy",
    "outputId": "deb744a0-7ce8-42f8-8cdf-d85770a1765c"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn_regressor = lambda: KNeighborsRegressor(n_neighbors=random.randint(1, 1000))\n",
    "\n",
    "default_knn_regr_RMSE, best_knn_regr_RMSE = \\\n",
    "    model_default_vs_tunned_compare(KNeighborsRegressor(), \\\n",
    "                                    knn_regressor, \\\n",
    "                                    prep_ko_temp_forecast_np,\\\n",
    "                                    next_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PPYtVjTzg6A0"
   },
   "source": [
    "## MLP\n",
    "Neurônios na camada do meio: de 5 a 20, de três em três"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "id": "IURKotCzgfVv",
    "outputId": "cc3c02d2-32e8-44fb-acf9-0fc9abe0ccae"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# Default hyperparameters\n",
    "default_mlp_regr_RMSE = x_val_positive_rmse(MLPRegressor(), \\\n",
    "                                            prep_ko_temp_forecast_np,\\\n",
    "                                            next_tmax)\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# Tunning hyperparams\n",
    "\n",
    "best_mlp_regr_RMSE = 10**3\n",
    "\n",
    "neurons = 5\n",
    "\n",
    "while neurons <= 20:\n",
    "    mlp_regressor = MLPRegressor(hidden_layer_sizes=neurons)\n",
    "    \n",
    "    mean_iter_scores = x_val_positive_rmse(mlp_regressor, \\\n",
    "                                           prep_ko_temp_forecast_np, next_tmax)\n",
    "    \n",
    "    if best_mlp_regr_RMSE > mean_iter_scores:\n",
    "        best_mlp_regr_RMSE = mean_iter_scores\n",
    "    \n",
    "    neurons +=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTzB4idS7KzK"
   },
   "source": [
    "## Arvore de decisão\n",
    "* Usando prunning com ccp_alpha sendo 10 números aleatórios entre 0.0 e 0.04.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dec_tree_regressor = lambda: DecisionTreeRegressor(ccp_alpha=random. \\\n",
    "                                                   uniform(0.0, 0.04))\n",
    "\n",
    "default_dec_tree_RMSE, best_dec_tree_RMSE = \\\n",
    "    model_default_vs_tunned_compare(DecisionTreeRegressor(), \\\n",
    "                                    dec_tree_regressor, \\\n",
    "                                    prep_ko_temp_forecast_np, \\\n",
    "                                    next_tmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Go_lWXJJ7QaN"
   },
   "source": [
    "## Random Forest\n",
    "Usando todas as combinações dos valores de n_estimators como 10, 100 e 1000 e max_features como 5, 10, e 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# Default hyperparameters\n",
    "default_rand_for_RMSE = x_val_positive_rmse(\\\n",
    "                            RandomForestRegressor(), \\\n",
    "                            prep_ko_temp_forecast_np, \\\n",
    "                            next_tmax)\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "# Tunning hyperparams\n",
    "\n",
    "best_rand_for_RMSE = 10**3\n",
    "n_estimators = [10, 100, 1000]\n",
    "max_features = [5, 10, 22]\n",
    "\n",
    "for estimator in n_estimators:\n",
    "    for max_feature in max_features:\n",
    "        dec_tree_regressor = RandomForestRegressor(n_estimators = estimator, \\\n",
    "                                                   max_features = max_feature)\n",
    "        mean_iter_scores = x_val_positive_rmse(dec_tree_regressor, \\\n",
    "                                               prep_ko_temp_forecast_np,\\\n",
    "                                               next_tmax)\n",
    "        \n",
    "        if best_rand_for_RMSE > mean_iter_scores:\n",
    "            best_rand_for_RMSE = mean_iter_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH0Ins5d7ks4"
   },
   "source": [
    "## GBM\n",
    "Selecionando 10 trincas aleatórias de n_estimators entre 5 e 100, learning_rate entre 0.01 e 0.3 e max_depth: 2 ou 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbm = lambda: GradientBoostingRegressor(\\\n",
    "                    max_depth = random.choice([2,3]), \\\n",
    "                    learning_rate = random.uniform(0.01, 0.3), \\\n",
    "                    n_estimators = random.randint(5, 100))\n",
    "\n",
    "default_gbm_RMSE, best_gbm_RMSE = \\\n",
    "    model_default_vs_tunned_compare(GradientBoostingRegressor(), \\\n",
    "                                    gbm,\\\n",
    "                                    prep_ko_temp_forecast_np,\\\n",
    "                                    next_tmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-Aw_09t7ueH"
   },
   "source": [
    "# Tabela final\n",
    "Tabela final com **cada classificador**, os **valores do RMSE** com valores default para os hiperparametros, e o **valor do RMSE** com o melhor valor dos hiperparametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "ZSoZ0nUckNaj"
   },
   "outputs": [],
   "source": [
    "columns = ['Regressor', 'RMSE default', 'RMSE melhores hiperparametros']\n",
    "data = [\n",
    "        ['Linear',            traditional_lr_rmse,    'N/A'], \\\n",
    "        ['Ridge',             default_ridge_lr_RMSE,   best_ridge_lr_RMSE], \\\n",
    "        ['Lasso',             default_lasso_lr_RMSE,   best_lasso_lr_RMSE], \\\n",
    "        ['SVR Linear',        default_svr_linear_RMSE, best_svr_linear_RMSE], \\\n",
    "        ['SVR RBF',           default_svr_rbf_RMSE,    best_svr_rbf_RMSE], \\\n",
    "        ['KNN',               default_knn_regr_RMSE,   best_knn_regr_RMSE], \\\n",
    "        ['MLP',               default_mlp_regr_RMSE,   best_mlp_regr_RMSE], \\\n",
    "        ['Arvore de decisao', default_dec_tree_RMSE,   best_dec_tree_RMSE], \\\n",
    "        ['Random Forest',     default_rand_for_RMSE,   best_rand_for_RMSE], \\\n",
    "        ['GBM',               default_gbm_RMSE,        best_gbm_RMSE], \\\n",
    "       ]\n",
    "\n",
    "final_table = pd.DataFrame(data, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "n6ZZipsb-UaS",
    "outputId": "55805c15-bbee-46b6-cc3f-f8ae21804150"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>RMSE default</th>\n",
       "      <th>RMSE melhores hiperparametros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear</td>\n",
       "      <td>1.447540</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>1.475565</td>\n",
       "      <td>1.440763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>1.975312</td>\n",
       "      <td>3.089508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVR Linear</td>\n",
       "      <td>1.463359</td>\n",
       "      <td>1.810254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVR RBF</td>\n",
       "      <td>1.199155</td>\n",
       "      <td>1.359733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.270178</td>\n",
       "      <td>1.685001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP</td>\n",
       "      <td>1.393400</td>\n",
       "      <td>1.882743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Arvore de decisao</td>\n",
       "      <td>1.528704</td>\n",
       "      <td>1.425551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.000956</td>\n",
       "      <td>0.940993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GBM</td>\n",
       "      <td>1.210508</td>\n",
       "      <td>1.276217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Regressor  RMSE default RMSE melhores hiperparametros\n",
       "0             Linear      1.447540                           N/A\n",
       "1              Ridge      1.475565                      1.440763\n",
       "2              Lasso      1.975312                      3.089508\n",
       "3         SVR Linear      1.463359                      1.810254\n",
       "4            SVR RBF      1.199155                      1.359733\n",
       "5                KNN      1.270178                      1.685001\n",
       "6                MLP      1.393400                      1.882743\n",
       "7  Arvore de decisao      1.528704                      1.425551\n",
       "8      Random Forest      1.000956                      0.940993\n",
       "9                GBM      1.210508                      1.276217"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "exercicio2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
